#!/usr/bin/env python
from pita.model import get_chrom_models
from pita.log import AnnotationLog
import os
import sys
import logging
import yaml
import argparse
import pysam
import subprocess
import pp
from tempfile import NamedTemporaryFile
from multiprocessing import Pool
from functools import partial

DEFAULT_CONFIG = "pita.yaml"
VALID_TYPES = ["bed", "gff", "gff3", "gtf"]

# Setup logging
formatter = logging.Formatter(fmt='%(asctime)s - %(levelname)s - %(module)s - %(message)s')
handler = logging.StreamHandler()
handler.setFormatter(formatter)
logger = logging.getLogger("pita")
logger.setLevel(logging.DEBUG)
logger.addHandler(handler)

p = argparse.ArgumentParser()
p.add_argument("-c",
               dest= "configfile",
               default = DEFAULT_CONFIG,
               help="Configuration file (default: {0})".format(DEFAULT_CONFIG)
              )

args = p.parse_args()
configfile = args.configfile

# Parse YAML config file
f = open(configfile, "r")
config = yaml.load(f)

# Data directory
base = "."
if config.has_key("data_path"):
    base = config["data_path"]

if not config.has_key("annotation") or len(config["annotation"]) == 0:
    print "No annotation files specified."
    sys.exit(1)

anno_files = []
chroms = {}
for d in config["annotation"]:
    logger.debug("annotation: {0}".format(d))
    fname = os.path.join(base, d["path"])
    t = d["type"].lower()
    if not t in VALID_TYPES:
        print "Invalid type: {0}".format(t)
        sys.exit(1)
    if not os.path.exists(fname):
        print "File does not exist: {0}".format(fname)
        sys.exit(1)
    else:
        tmp = NamedTemporaryFile()
        preset = "gff"
        if t == "bed":
            cmd = "sort -k1,1 -k2g,2 {0} | grep -v track | grep -v \"^#\" > {1}"
            preset = "bed"
        elif t in ["gff", "gff3", "gtf3"]:
            cmd = "sort -k1,1 -k4g,4 {0} | grep -v \"^#\" > {1}"
        
        # Sort the input file
        logger.debug(cmd.format(fname, tmp.name))
        subprocess.call(cmd.format(fname, tmp.name), shell=True)
        # Compress using bgzip
        logger.debug("compressing {0}".format(tmp.name))
        tabix_file = tmp.name + ".gz"
        pysam.tabix_compress(tmp.name, tabix_file)
        # Index (using tabix command line, as pysam.index results in a Segmentation fault
        logger.debug("indexing {0}".format(tabix_file))
        subprocess.call("tabix {0} -p {1}".format(tabix_file, preset), shell=True)
        # Add file info
        anno_files.append([d["name"], tabix_file, t])
        # Save chromosome names
        for chrom in pysam.Tabixfile(tabix_file).contigs:
            chroms[chrom] = 1

# data  config
data = []
for d in config["data"]:
    logger.debug("data: {0}".format(d))
    d.setdefault("up", 0)
    d.setdefault("down", 0)
    row = [d["name"], os.path.join(base, d["path"]), d["feature"], (d["up"], d["down"])]
    data.append(row)

weight = {}
if config.has_key("scoring"):
    weight = config["scoring"]

line_format = "{0}\t{1}\t{2}\t{3}\t{4}\t{5}\t{6}\t{7}\t{8}\t{9}\t{10}\t{11}"
print 'track name="pita_test"'
chroms = chroms.keys()
#chroms = ["JGIv7b.000000004", "JGIv7b.000087017"]

alog = AnnotationLog()
for name in [x[0] for x in anno_files]:
    alog.add(name)

def annotate_chrom(chrom, anno_files, data, weight):
    ret = []
    for row in get_chrom_models(chrom, anno_files, data, weight):
        ret.append(row)
    return ret

partialAnnotate = partial(annotate_chrom, anno_files=anno_files, data=data, weight=weight)

pool = Pool() 
results = pool.map(partialAnnotate, chroms) 
pool.close()
pool.join() 

for result in results:
    for genename,exons,cluster in result:
        chrom = exons[0].chr
        chromStart = exons[0].start
        chromEnd = exons[-1].end
        sizes = ",".join([str(exon.end - exon.start) for exon in exons]) + ","
        starts = ",".join([str(exon.start - chromStart) for exon in exons]) + ","
        print line_format.format(
                                chrom, 
                                chromStart, 
                                chromEnd, 
                                genename, 
                                600, 
                                exons[0].strand, 
                                chromStart, 
                                chromEnd, 
                                "0,0,0", 
                                len(exons), 
                                sizes, 
                                starts
                                )
        alog.log_to_file(genename, exons, cluster)
