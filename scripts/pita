#!/usr/bin/env python
from pita.collection2 import Collection
from pita.io import read_gff_transcripts, read_bed_transcripts
import os
import sys
import logging
import yaml
import argparse

DEFAULT_CONFIG = "pita.yaml"
VALID_TYPES = ["bed", "gff", "gff3", "gtf"]

# Setup logging
formatter = logging.Formatter(fmt='%(asctime)s - %(levelname)s - %(module)s - %(message)s')
handler = logging.StreamHandler()
handler.setFormatter(formatter)
logger = logging.getLogger("pita")
logger.setLevel(logging.INFO)
logger.addHandler(handler)

p = argparse.ArgumentParser()
p.add_argument("-c",
               dest= "configfile",
               default = DEFAULT_CONFIG,
               help="Configuration file (default: {0})".format(DEFAULT_CONFIG)
              )

args = p.parse_args()
configfile = args.configfile

# Parse YAML config file
f = open(configfile, "r")
config = yaml.load(f)

# Data directory
base = "."
if config.has_key("data_path"):
    base = config["data_path"]

if not config.has_key("annotation") or len(config["annotation"]) == 0:
    print "No annotation files specified."
    sys.exit(1)

for d in config["annotation"]:
    logger.debug("annotation: {0}".format(d))
    fname = os.path.join(base, d["path"])
    t = d["type"].lower()
    if not t in VALID_TYPES:
        print "Invalid type: {0}".format(t)
        sys.exit(1)
    if not os.path.exists(fname):
        print "File does not exist: {0}".format(fname)
        sys.exit(1)
    
data = []
for d in config["data"]:
    logger.debug("data: {0}".format(d))
    d.setdefault("up", 0)
    d.setdefault("down", 0)
    row = [d["name"], os.path.join(base, d["path"]), d["feature"], (d["up"], d["down"])]
    data.append(row)

# Read annotation files
mc = Collection()
for f in config["annotation"]:
    fname = os.path.join(base, f["path"])
    logger.info("Reading annotation from {0}".format(fname))
    if f["type"] == "bed":
        it = read_bed_transcripts(fname, 3)
    elif f["type"] in ["gff", "gtf", "gff3"]:
        it = read_gff_transcripts(fname, 3)
    for tname, source, exons in it:
        mc.add_transcript("{0}:{1}".format(f["name"], tname), source, exons)

for name, fname, span, extend in data:
    logger.info("Reading data {0} from {1}".format(name, fname))
    mc.get_read_statistics(fname, name=name, span=span, extend=extend)

def get_updated_exons(model, name):
    strand = model[0].strand
    n = 0
    u5 = 0
    u3 = 0
    for e in best_exons:
        if name in [x.split(":")[0] for x in e.evidence]:
            break
        n += 1

    if strand == "-":
        u3 = n
    else:
        u5 = n 
     
    n = 0
    for e in best_exons[::-1]:
        if name in [x.split(":")[0] for x in e.evidence]:
            break
        n += 1

    if strand == "-":
        u5 = n
    else:
        u3 = n
    
    return u5,u3

log_header = "Model\tNr. Exons\tExons in best model\tExons in other models\tUpdated 5'\tUpdated 3'\tOriginal models\n"
logs = {}
for name in [x["name"] for x in config["annotation"]]:
    logs[name] = open("pita.{0}.log".format(name), "w")
    logs[name].write(log_header)

print 'track name="pita_test"'
for i, cluster in enumerate(mc.get_all_transcript_clusters()):
    
    m = mc.max_weight(cluster, {"RNAseq": 1, "H3K4me3":2}, {"RNAseq": "all", "H3K4me3":"first"})
    #m = mc.max_weight(cluster, {"RNAseq": 1}, {"RNAseq": "all"})
    #m = mc.max_weight(cluster, {}, {}) 
    exons = m
    chrom = exons[0].chr
    chromStart = exons[0].start
    chromEnd = exons[-1].end
    genename = "{0}:{1}-{2}_".format(chrom, chromStart, chromEnd)
    #if mc.get_weight(m, "H3K4me3.peaks", "first") > 0:
    if mc.get_weight(m, "H3K4me3", "first") > 100:
        genename += "V"
    else:
        genename += "X"
   
    x = mc.get_weight(m, "RNAseq", "all") / (sum([e.end - e.start for e in m]) / 1000.0)
    if x > 5:
        genename += "V"
    else:
        genename += "X"
    
    best_exons = [e for e in m]
    best_ev = {}
    for e in best_exons:
        for ev in set([x.split(":")[0] for x in e.evidence]):
            best_ev[ev] = best_ev.setdefault(ev, 0) + 1
    other_exons = []
    other_ev = {}
    for o in cluster:
        for e in o:
            if not (e in best_exons or e in other_exons):
                other_exons.append(e)
                for ev in set([x.split(":")[0] for x in e.evidence]):
                    other_ev[ev] = other_ev.setdefault(ev, 0) + 1
    
    for name in [x["name"] for x in config["annotation"]]:
        ev = []
        for e in best_exons + other_exons:
            for evidence in e.evidence:
                ev.append(evidence.split(":"))
        orig_models = {}
        for (origin,orig_name) in ev:
            if origin == name:
                orig_models[orig_name] = orig_models.setdefault(orig_name, 0) + 1

        u5, u3 = get_updated_exons(m, name)
        logs[name].write("{0}\t{1}\t{2}\t{3}\t{4}\t{5}\t{6}\n".format(
                                                       genename,
                                                       len(m),
                                                       best_ev.setdefault(name, 0),
                                                       other_ev.setdefault(name, 0),
                                                       u5,
                                                       u3,
                                                       ",".join(orig_models.keys())
                                                       )
                         )

    sizes = ",".join([str(exon.end - exon.start) for exon in exons]) + ","
    starts = ",".join([str(exon.start - chromStart) for exon in exons]) + ","
    print "%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s\t%s" % (chrom, chromStart, chromEnd, genename, 600, exons[0].strand, chromStart, chromEnd, 0, len(exons), sizes, starts)

for f in logs.values():
    f.close()
