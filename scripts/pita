#!/usr/bin/env python
from pita.model import get_chrom_models
from pita.util import model_to_bed
from pita.log import AnnotationLog
import os
import sys
import logging
import yaml
import argparse
import pysam
import subprocess
import pp
from tempfile import NamedTemporaryFile
import multiprocessing as mp
from functools import partial
import signal

DEFAULT_CONFIG = "pita.yaml"
DEFAULT_THREADS = 4
VALID_TYPES = ["bed", "gff", "gff3", "gtf"]

p = argparse.ArgumentParser()
p.add_argument("-c",
               dest= "configfile",
               default = DEFAULT_CONFIG,
               help="Configuration file (default: {0})".format(DEFAULT_CONFIG)
              )
p.add_argument("-t",
               dest= "threads",
               default = DEFAULT_THREADS,
               type = int,
               help="Number of threads (default: {0})".format(DEFAULT_THREADS)
              )
p.add_argument("-i",
               dest= "index_dir",
               default = None,
               help="Genome index dir"
              )

args = p.parse_args()
configfile = args.configfile
threads = args.threads
index = args.index_dir

basename = os.path.splitext(configfile)[0]

# Setup logging
logger = logging.getLogger("pita")
logger.setLevel(logging.DEBUG)
formatter = logging.Formatter(fmt='%(asctime)s - %(levelname)s - %(module)s - %(message)s')
handler = logging.StreamHandler()
handler.setFormatter(formatter)
handler.setLevel(logging.INFO)
fh = logging.FileHandler("{0}.log".format(basename))
fh.setFormatter(formatter)
fh.setLevel(logging.DEBUG)
logger.addHandler(handler)
logger.addHandler(fh)

# Parse YAML config file
f = open(configfile, "r")
config = yaml.load(f)

# Data directory
base = "."
if config.has_key("data_path"):
    base = config["data_path"]


prune = None
if config.has_key("prune_overlap"):
    prune = config["prune_overlap"]

if not config.has_key("annotation") or len(config["annotation"]) == 0:
    logger.error("No annotation files specified.")
    sys.exit(1)

anno_files = []
chroms = {}
for d in config["annotation"]:
    logger.debug("annotation: {0}".format(d))
    fname = os.path.join(base, d["path"])
    t = d["type"].lower()
    if not t in VALID_TYPES:
        logger.error("Invalid type: {0}".format(t))
        sys.exit(1)
    if not os.path.exists(fname):
        logger.error("File does not exist: {0}".format(fname))
        sys.exit(1)
    else:
        logger.info("Creating tabix index for {0}".format(os.path.basename(fname)))
        logger.debug("Preparing {0} for tabix".format(fname))
        tmp = NamedTemporaryFile(prefix="pita")
        preset = "gff"
        if t == "bed":
            cmd = "sort -k1,1 -k2g,2 {0} | grep -v track | grep -v \"^#\" > {1}"
            preset = "bed"
        elif t in ["gff", "gff3", "gtf3"]:
            cmd = "sort -k1,1 -k4g,4 {0} | grep -v \"^#\" > {1}"
        
        # Sort the input file
        logger.debug(cmd.format(fname, tmp.name))
        subprocess.call(cmd.format(fname, tmp.name), shell=True)
        # Compress using bgzip
        logger.debug("compressing {0}".format(tmp.name))
        tabix_file = tmp.name + ".gz"
        pysam.tabix_compress(tmp.name, tabix_file)
        tmp.close()
        # Index (using tabix command line, as pysam.index results in a Segmentation fault
        logger.debug("indexing {0}".format(tabix_file))
        subprocess.call("tabix {0} -p {1}".format(tabix_file, preset), shell=True)
        
        #fobj = pysam.Tabixfile(tabix_file)
        # Add file info
        anno_files.append([d["name"], tabix_file, t])
        # Save chromosome names
        for chrom in pysam.Tabixfile(tabix_file).contigs:
            chroms[chrom] = 1

# data  config
data = []
if config.has_key("data") and config["data"]:
    for d in config["data"]:
        logger.debug("data: {0}".format(d))
        d.setdefault("up", 0)
        d.setdefault("down", 0)
        if type("") == type(d["path"]):
            d["path"] = [d["path"]]
       

        fnames = [os.path.join(base, x) for x in d["path"]]
        for fname in fnames:
            if not os.path.exists(fname):
                logger.error("File does not exist: {0}".format(fname))
                sys.exit(1)
          
        row = [d["name"], fnames, d["feature"], (d["up"], d["down"])]
        data.append(row)

weight = {}
if config.has_key("scoring"):
    weight = config["scoring"]

line_format = "{0}\t{1}\t{2}\t{3}\t{4}\t{5}\t{6}\t{7}\t{8}\t{9}\t{10}\t{11}"
print 'track name="{0}"'.format(basename)
chroms = chroms.keys()

if config.has_key("chromosomes") and config["chromosomes"]:
    if type(config["chromosomes"]) == type([]):
        chroms = config["chromosomes"]
    else:
        chroms = [config["chromosomes"]]

def init_worker():
    signal.signal(signal.SIGINT, signal.SIG_IGN)

def print_output(alog, genename, exons,  ev, best_ev, other_ev):
    print model_to_bed(exons, genename)
    alog.log_to_file(genename, exons,  ev, best_ev, other_ev ) 

def listener(q, names, append=False):
    '''listens for messages on the q, writes to file. '''

    alog = AnnotationLog(append)
    for name in names:
        alog.add(name)
    
    while 1:
        m = q.get()
        if m == 'kill':
            break
       
        genename, exons,  ev, best_ev, other_ev = m
        logger.debug("calling print_output for {0}".format(genename))
        print_output(alog, genename, exons,  ev, best_ev, other_ev)

def annotate_chrom(chrom, q, anno_files, data, weight, prune, index):
    logger.info("Chromosome {0} started".format(chrom))
    for genename, best_exons, ev, best_ev, other_ev in get_chrom_models(chrom, anno_files, data, weight, prune, index):
        logger.debug("Putting {0} in print queue".format(genename))
        q.put([genename, best_exons, ev, best_ev, other_ev])

    logger.info("Chromosome {0} finished".format(chrom))

if threads > 1:

    manager = mp.Manager()
    q = manager.Queue()    

    pool = mp.Pool(threads, init_worker) 
    try:    
        partialAnnotate = partial(annotate_chrom, q=q, anno_files=anno_files, data=data, weight=weight, prune=prune, index=index)
        #put listener to work first
        watcher = pool.apply_async(listener, (q,[x[0] for x in anno_files], False))
        pool.map(partialAnnotate, chroms) 
        q.put('kill')
        pool.close()
        pool.join()
    except KeyboardInterrupt:
        logger.exception("Caught KeyboardInterrupt, terminating workers")
        pool.terminate()
        pool.join()
else:
    alog = AnnotationLog(append=False)
    for name in [x[0] for x in anno_files]:
        alog.add(name)
    
    for chrom in chroms:
        for genename,best_exons, ev, best_ev, other_ev in get_chrom_models(chrom, anno_files, data, weight, prune, index):
            print_output(alog, genename,best_exons, ev, best_ev, other_ev)
